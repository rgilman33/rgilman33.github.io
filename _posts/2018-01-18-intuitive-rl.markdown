---
layout: post
title:  "Intuitive RL: Intro to A2C"
description: "RL in comic form. Intro to the advantage-actor-critic model (A2C). If you understand the A2C, you understand deep RL"
date:   2018-01-18
categories: reinforcement-learning
---

*Originally posted at [Hacker Noon](https://medium.com/hackernoon/intuitive-rl-intro-to-advantage-actor-critic-a2c-4ff545978752)*

Reinforcement learning (RL) practitioners have produced a number of excellent tutorials. Most, however, describe RL in terms of mathematical equations and abstract diagrams. We like to think of the field from a different perspective. RL itself is inspired by how animals learn, so why not translate the underlying RL machinery back into the natural phenomena theyâ€™re designed to mimic? Humans learn best through stories.

This is a story about the Actor Advantage Critic (A2C) model. Actor-Critic models are a popular form of Policy Gradient model, which is itself a vanilla RL algorithm. If you understand the A2C, you understand deep RL.

Corresponding [code here](https://github.com/rgilman33/simple-A2C-PPO). Download the [high-res comic here](/assets/img/RLComicMerged_med.png). Art by [@embermarke](https://twitter.com/embermarke)

![A2C comic](/assets/img/a2c.jpeg)